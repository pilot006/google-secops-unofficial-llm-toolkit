{"Name":"Anthropic Claude on Vertex AI - Get Text Response","Description":"Get response from Anthopic's Claude model hosted on Vertex AI","Script":"from SiemplifyAction import SiemplifyAction\nfrom SiemplifyUtils import unix_now, convert_unixtime_to_datetime, output_handler\nfrom ScriptResult import EXECUTION_STATE_COMPLETED, EXECUTION_STATE_FAILED,EXECUTION_STATE_TIMEDOUT\nimport google.auth.transport.requests\nfrom google.oauth2 import service_account\nimport json\nimport requests\n\n@output_handler\n\ndef main():\n    siemplify = SiemplifyAction()\n\n    SA_JSON = siemplify.extract_action_param(\"Service Account JSON\", print_value=False)\n    SA_JSON = json.loads(SA_JSON)\n    PROJECT_ID = siemplify.extract_action_param(\"GCP Project ID\", print_value=False)\n    REGION = siemplify.extract_action_param(\"GCP Region\", print_value=False)\n    inbound_prompt = siemplify.extract_action_param(\"Prompt\", print_value=True)\n    MODEL_ID = siemplify.extract_action_param(\"Model Resource ID\", print_value=True)\n    \n    endpoint = 'https://' + REGION\n    endpoint = endpoint + '-aiplatform.googleapis.com/v1/projects/' \n    endpoint = endpoint + PROJECT_ID + \"/locations/\" + REGION\n    endpoint = endpoint + '/publishers/google/models/' + MODEL_ID + ':streamGenerateContent'\n    siemplify.LOGGER.info(\"endpoint: \" + endpoint)\n\n    # Gemini model structure\n    llm_prompt = {\n                    \"contents\": {\n                        \"role\": \"user\",\n                        \"parts\": {\n                            \"text\": inbound_prompt\n                        }\n                    }\n                }\n    credentials = service_account.Credentials.from_service_account_info(\n        SA_JSON, scopes=['https://www.googleapis.com/auth/cloud-platform']\n        )\n    request = google.auth.transport.requests.Request()\n    credentials.refresh(request)\n    hd = {\n      \"Authorization\": \"Bearer \" + credentials.token,\n      \"Content-Type\": \"application/json\"\n    }\n    req = requests.post(endpoint, headers=hd, json=llm_prompt)\n    r_json = json.loads(req.text)\n    siemplify.LOGGER.info(r_json)\n    siemplify.result.add_result_json(r_json)\n    full_txt = \"\"\n\n    # The response comes back in a multi-part array, which we'll choose the first candidate and combine\n    for i in r_json:\n        if 'parts' in str(i):\n            full_txt = full_txt + (i['candidates'][0]['content']['parts'][0]['text'])\n\n    status = EXECUTION_STATE_COMPLETED\n    output_message = full_txt\n    result_value = full_txt\n\n    siemplify.LOGGER.info(\"\\n  status: {}\\n  result_value: {}\\n  output_message: {}\".format(status,result_value, output_message))\n    siemplify.end(output_message, result_value, status)\n\n\nif __name__ == \"__main__\":\n    main()\n","IntegrationIdentifier":"LLM Toolkit","ScriptResultName":"ScriptResult","DynamicResultsMetadata":[{"ResultName":"JsonResult","ResultExample":"{}","ShowResult":true}],"Creator":"036fe879-4c16-461e-b6d9-b1c552806fa0","IsEnabled":true,"IsCustom":true,"IsSystem":false,"Version":25.0,"TimeoutSeconds":600,"IsAsync":false,"AsyncPollingIntervalInSeconds":3600,"TotalIntervalTimeoutForAsyncInSeconds":86400,"Parameters":[{"CustomActionId":0,"IsMandatory":true,"DefaultValue":"Hello world!","Description":"Prompt that you want the Gemini model to respond to","Name":"Prompt","Value":"Hello world!","Type":0,"OptionalValues":null,"OptionalValuesJson":null},{"CustomActionId":0,"IsMandatory":true,"DefaultValue":"claude-3-5-sonnet@20240620","Description":"Resource ID of the Anthopic model you want to use. We'll default to  Claude 3.5 Sonnet","Name":"Model Resource ID","Value":"claude-3-5-sonnet@20240620","Type":0,"OptionalValues":null,"OptionalValuesJson":null},{"CustomActionId":0,"IsMandatory":true,"DefaultValue":"{\n  \"type\": \"service_account\",\n  \"project_id\": \"acme\",\n  \"private_key_id\": \"1234\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\n1234\\n-----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"user@acme.com\",\n  \"client_id\": \"1234\",\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n  \"token_uri\": \"https://accounts.google.com/o/oauth2/token\",\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/user@acme.com\"\n}","Description":"Service account JSON with rights to call the Gemini model on Vertex AI","Name":"Service Account JSON","Value":"{\n  \"type\": \"service_account\",\n  \"project_id\": \"acme\",\n  \"private_key_id\": \"1234\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\n1234\\n-----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"user@acme.com\",\n  \"client_id\": \"1234\",\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n  \"token_uri\": \"https://accounts.google.com/o/oauth2/token\",\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/user@acme.com\"\n}","Type":12,"OptionalValues":null,"OptionalValuesJson":null},{"CustomActionId":0,"IsMandatory":true,"DefaultValue":"my-google-project","Description":"Project ID for Google Cloud project with Vertex AI enabled","Name":"GCP Project ID","Value":"my-google-project","Type":0,"OptionalValues":null,"OptionalValuesJson":null},{"CustomActionId":0,"IsMandatory":true,"DefaultValue":"us-central1","Description":"Region that the model is hosted in","Name":"GCP Region","Value":"us-central1","Type":0,"OptionalValues":null,"OptionalValuesJson":null}],"DefaultResultValue":"","PythonVersion":"None","SimulationData":{"Entities":null},"SimulationDataJson":null}